---
editor_options:
  chunk_output_type: inline
title: "Routinely Randomize Potential Sources of Measurement Reactivity to Estimate and Adjust for Biases in Subjective Reports"
output: 
  html_document: 
    number_sections: yes
    toc: yes
    toc_depth: 3
---


```{r}
options(stringsAsFactors = FALSE)
#' show two significant digits tops
options(digits = 2)
#' tend not to show scientific notation, because we're just psychologists
options(scipen = 7)
#' make output a bit wider
options(width = 110)
#' set a seed to make analyses depending on random number generation reproducible
set.seed(1710) # if you use your significant other's birthday make sure you stay together for the sake of reproducibility


#' ## Load packages
#' generate the site
library(rmarkdown)
#' set options for chunks
library(knitr)
#' my formr utility package to generate e.g. the bibliography
library(formr)
#' pretty-printed output
library(pander)
#' tidyverse date times
library(lubridate)
#' tidyverse strings
library(stringr)
#' extractor functions for models
library(broom)
#' grammar of graphics plots
library(ggplot2)
#' svg graphs
# library(svglite);
library(feather)
library(ggthemes)
library(codebook)
library(kableExtra)
library(Cairo)
library(paletteer)

#' tidyverse: has a lot of naming conflicts, so always load last
library(tidyverse)
opts_chunk$set(warning = F, message = F, error = TRUE, fig.width = 13, fig.height = 10)
library(broom.mixed)
library(tidylog)
options(width = 4000)
theme_set(theme_classic() + theme_pander(base_size = 18))
```


```{r}
key <- keyring::key_get_raw("encrypt_data_routinely_randomise")
class(key) <- c("aes", "raw")
key <- cyphr::key_openssl(key)
s3_daily_id_answered <- cyphr::decrypt(readRDS("s3_daily_id_answered.rds"), key)
diary <- cyphr::decrypt(readRDS("diary.rds"), key)

s3_daily_id_answered <-  rio::import("../routine_and_sex/data/s3_daily_id_answered.feather")

first_page = s3_daily_id_answered  %>% 
  filter(item_name %in% c("irritable", "self_esteem", "risk_taking", "good_mood", "loneliness", "stressed")) %>% 
  group_by(session, unit_session_id) %>% 
  mutate(display_order = min_rank(display_order),
         number_of_items_shown = n()) %>%  
  arrange(session, unit_session_id, display_order) %>% 
  mutate(
        last_item = if_na(lag(label_english), "[None]")) %>% 
  ungroup() %>% 
  mutate(last_item = relevel(factor(last_item), ref =  "[None]"))
```




# Description
The following items were shown in random order on the first page of our diary. 

- I was stressed. (40% probability of being shown)
- I was lonely. (40%)
- My mood was good. (80%)
- I was prepared to take risks. (20%)
- I was satisfied with myself. (80%)
- I was irritable. (40%)

Participants (n=`r n_distinct(first_page$session)` women) could answer on a 5 point likert scale from "less than usual" [0] to "more than usual" [4]. Pole labels were placed left and right of blank, equally sized buttons. Participants answered the diary on `r nrow(diary)` days in total, or on `r round(nrow(diary)/n_distinct(first_page$session))` days per woman.
Because of our planned missing design with randomised display and order, participants saw only a subset of these items each day. Therefore, the following were randomised variables
- the day an item was first shown (conditional on adjusting for day number), 
- the number of times an item was seen previously (conditional as above). 
- the number of items on that day.
- the display order.

## Table 1
```{r}
first_page %>% mutate(days_tot = n_distinct(created)) %>% group_by(label_english) %>% 
  summarise(women = n_distinct(session),
            days = n_distinct(unit_session_id),
            per_woman = round(days/women),
            mean = sprintf("%.2f", mean(answer, na.rm = T)),
            sd = sprintf("%.2f", sd(answer, na.rm = T)),
  pct_shown = round(days/first(days_tot),1)) %>% 
  knitr::kable()
```

## Table 2
```{r}
first_page %>% 
  mutate(first_day_of_item = if_else(first_day_of_item > 6, "7+", as.character(first_day_of_item))) %>% 
  group_by(label_english) %>% 
  mutate(n_subjects = n_distinct(session)) %>% 
  group_by(label_english, first_day_of_item) %>% 
  summarise(n = paste0(n_distinct(session), " (", round(n_distinct(session)/first(n_subjects) * 100), "%)")) %>% 
  spread(first_day_of_item, n, fill = 0) %>% 
  kable(caption = "Number of women who first saw each item on the first, second, ..., n-th day.")
```

Information for the narrative description of the study.

```{r}
skimr::skim_with(haven_labelled = skimr::get_skimmers()$numeric)
all_surveys <- diary %>% select(session, didntmissfirstweek, hetero_relationship,
                          age, education_years, has_children, nr_children, relationship_status,
                          occupational_status)

first_page %>% group_by(session, unit_session_id) %>% 
  summarise(answered = any(!is.na(answer))) %>% 
  summarise(days = sum(answered)) %>% 
  select(days) %>% 
  skimr::skim_to_wide() %>% 
  knitr::kable()

all_surveys %>% 
  haven::zap_labels() %>% 
  select(age, hetero_relationship, education_years, has_children, nr_children) %>% skimr::skim_to_wide() %>% 
  knitr::kable()

occupational_status <- all_surveys$occupational_status
sort(round(props(occupational_status),2)) %>% 
  knitr::kable()
sort(round(props(occupational_status %contains% "student"),2))
sort(round(props(occupational_status %contains% "employed"),2))

relationship_status <- all_surveys$relationship_status
sort(round(props(haven::as_factor(relationship_status)),2))
codebook::plot_labelled(relationship_status) + coord_flip()

first_page %>% 
  mutate(first_day_of_item = if_else(first_day_of_item > 6, "7+", as.character(first_day_of_item))) %>% 
  group_by(item_name, first_day_of_item) %>% 
  summarise(n = n_distinct(session)) %>% 
  spread(first_day_of_item, n, fill = 0)# %>% 
  ungroup() %>% 
  select(-item_name) %>% 
  rowSums()
```


# Bias tests

## Figure 1
We showed above that responses do not drift much over time in the diary. But do
participants learn to respond more quickly?

```{r}
first_page %>% filter(response_time_since_previous < 1*30*1000, response_time_since_previous > 0, display_order > 1) %>% 
  ggplot(., aes(day_number, response_time_since_previous/1000)) + 
  geom_pointrange(alpha = 0.3, position = position_dodge(width = 0.2), stat ='summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat ='summary', fun.y = function(x) { mean(x, na.rm =T, trim = 0.10) }) +
  scale_y_continuous("Response time (in s) since previous item") +
  facet_wrap(~ label_english)

ggsave(width = 10, height = 8, filename = "Figure1.png")
```

## Figure 2:  Initial elevation

In this graph, we show mean response to the item, depending on which day of the diary
we first asked it. Different-coloured lines reflect different starting days. 
We only show lines based on at least twenty participants to reduce noise. Therefore,
fewer lines are shown for items with a higher probability of being shown.
Wherever the initial point of each line exceeds the mean of the other lines on the day,
this would be evidence for initial elevation bias.

In this graph, we show the first week. The Y axes include the global mean Â± 1 global standard deviation for each item.

```{r layout='l-screen-inset',fig.width=15,fig.height=8}
first_page %>% 
  filter(day_number < 7) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE)) %>% 
  group_by(item_name, day_number, first_day_of_item_factor) %>% 
  filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day_number, answer, colour = first_day_of_item_factor)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = group_mean, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat = 'summary', fun.data = 'mean_se') + 
  scale_color_colorblind("First day the\nitem was shown") +
  scale_y_continuous("Response") +
  facet_wrap(~ label_english, scales = "free_y", nrow = 2) + 
  scale_x_continuous("Day number", breaks = 0:10)
ggsave(width = 15, height = 8, filename = "Figure2.png")
```


## Figure 3: Item order
The item order on each page was randomised too. If the mechanism for initial 
elevation bias involves familiarity with the response scale, we might expect
to find that the first item on the first page on the first day is answered differently
than later responses. Different mechanisms of response bias (e.g., amount of mouse movement required to reply is equal for all responses for the first item, but reduced for unchanged responses to lower down items) could lead to different response biases according to item order.

Item order is confounded with another randomised variable, namely the number
of items shown on each page. For example, an item order of six only occurs when all six items were shown.

```{r}
first_page %>%
  ggplot(., aes(display_order, answer)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  # geom_smooth(aes(group = session), method = 'lm', color = "#00000011", se = FALSE) +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat = 'summary', fun.data = 'mean_se') + 
  scale_y_continuous("Response") +
  scale_x_continuous("Item order", breaks = 1:6) +
  facet_wrap(~ label_english, scales = 'free_y')

ggsave(width = 15, height = 8, filename = "Figure3.png")
```



## Figure 4: Last item identity
Given that item order is randomised, it seems fruitful to examine whether the
previous question biases the next. This would be a potential mechanism for item
order effects. Some differences are apparent, though minute,


```{r,fig.width = 15, fig.height = 8}
first_page %>% 
  left_join(
    first_page %>% select(last_item = item_name, last_item_label = label_english) %>% distinct()
  ) %>% 
  mutate(last_item = relevel(fct_explicit_na(str_wrap(last_item_label, 20), "[None]"), "[None]")) %>% 
  ggplot(., aes(last_item, answer)) +
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = item_mean), linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat ='summary', fun.data = 'mean_se') + 
  # geom_line(position = position_dodge(width = 0.4), stat ='summary', fun.data = 'median_hilow') + 
  scale_y_continuous("Response") +
  scale_x_discrete("Preceding item") +
  coord_flip() +
  facet_wrap(~ label_english, scales = 'free_x')

ggsave(width = 15, height = 8, filename = "Figure4.png")
```

## Figure 5: Number of items shown
As mentioned above, the number of items shown is also a randomised variable.
It is in turn confounded with item order, because items shown on a page with more items
are likely to have a later item order. Most importantly, when only one item is shown, item order
is also one. As above, we can not only examine the mean but also the relative frequencies of 
each response.

```{r}
first_page %>% 
  group_by(label_english, item_name, number_of_items_shown) %>% 
  mutate(group_n = n_nonmissing(answer)) %>% 
  group_by(label_english, item_name, number_of_items_shown, answer) %>% 
  summarise(rel_freq = n_nonmissing(answer)/first(group_n)) %>% 
  ggplot(., aes(answer, y = rel_freq, colour = number_of_items_shown, group = number_of_items_shown)) + 
  geom_line(position = position_dodge(width = 0.2)) + 
  scale_color_continuous("Number of\nitems shown") +
  scale_y_continuous("Relative frequency") +
  scale_x_continuous("Response", breaks = 0:4, labels = c("[0] less\nthan\nusual", 1, 2, 3, "[4] more\nthan\nusual")) +
  facet_wrap(~ label_english, scales = "free_y")

ggsave(width = 15, height = 8, filename = "Figure5.png")
```


### Continuous predictors
```{r fig.width=12, fig.height=6}
predictors <- first_page %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )
library(lme4)
library(lmerTest)
library(broom.mixed)
complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ items_shown + item_order + times_item_shown + poly(scale(day_number, scale=F)/10, degree = 3, raw = T) + refer_time_period +  (1 | session), data = .))

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + times_item_shown + poly(scale(day_number, scale=F)/10, degree = 3, raw = T) + refer_time_period +  (1 | session), data = .))

all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.99)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    first_page %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(term, 
                           "R. No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "R. No. items shown" = "items_shown",
                           "R. Item order" = "item_order",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "R. No. items shown", 
                           "R. No. times item shown", 
                           "R. Item order",
                           "Ref: since last entry",
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.35, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  coord_flip()

ggsave(width = 12, height = 6, filename = "Figure6.png")
```

## Figure 7: Response time Multilevel models

Testing the times the item was seen already (reference category: first day) as a factor variable, rather than yes/no.

adjusting for day number (0 to 7+), the time period referred to (affected by how often people have responded so far), which day the item was first shown, the day number, and a random effect for the woman.

```{r fig.width=10,fig.height=8}
predictors <- first_page %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )

predictors <- predictors %>% 
  filter(response_time_since_previous < 30*1000, response_time_since_previous > 0,
         item_order != "1")

library(lme4)
library(lmerTest)

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(response_time_since_previous/1000 ~ items_shown + item_order + times_item_shown + poly(scale(day_number, scale=F)/10, degree = 3, raw = T) + refer_time_period +  (1 | session), data = .))
# summary(lmer(response_time_since_previous/1000 ~ items_shown + item_order + times_item_shown + poly(scale(day_number, scale=F)/10, degree = 3, raw = T) + refer_time_period +  (1 | session), data = predictors %>% filter(item_name == 'good_mood')))
# qplot(predictors$response_time_since_previous/1000)

initial_elevation_bias_rt <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.99)) %>% 
  bind_rows(.id = "response") 


initial_elevation_bias_rt %>% 
  left_join(first_page %>% select(response = item_name, label_english) %>% unique()) %>% 
  filter(term != "refer_time_periodlast entry", term != "(Intercept)", !is.na(conf.high)) %>% 
  mutate(term = fct_relevel(fct_recode(term, 
                           "R. No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "R. No. items shown" = "items_shown",
                           "R. Item order" = "item_order",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "R. No. items shown", 
                           "R. No. times item shown", 
                           "R. Item order",
                           "Ref: since last entry",
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>%
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_pointrange() +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.35, segment.size = 0) +
  scale_y_continuous("Estimated effect on response time (in s)") +
  facet_wrap(~ label_english) +
  coord_flip()

ggsave(width = 12, height = 6, filename = "Figure7.png")
```




## Figure 8: Dropout
The additional workload on each day (total number of randomised items that were shown)
is a random variable, conditional on relationship status (women in relationships had
to answer slightly more questions, some of which were also randomised in appearance). 
We can use this variable to predict whether a woman who had to answer more questions
is less likely to answer the diary on the next day.

```{r}

qplot(diary$lag_nr_items_day)
crosstabs(~ did_not_finish_entry + skipped_day, diary)

ggplot(diary, aes(nr_items_day_done, fill = factor(hetero_relationship))) + 
  geom_bar() +
  scale_fill_colorblind(guide = FALSE) +
  facet_wrap(~ hetero_relationship, labeller = as_labeller(c("0" = "single", "1" = "in relationship")))


ggplot(diary %>% group_by(hetero_relationship, lag_nr_items_day) %>% 
         summarise(count = n(),
                   skip = mean(skipped_day, na.rm = T)), aes(lag_nr_items_day, count, fill = skip)) + 
  geom_bar(stat = 'identity') +
  scale_color_viridis_c() +
  facet_wrap(~ hetero_relationship, labeller = as_labeller(c("0" = "single", "1" = "in relationship")))

ggplot(diary, aes(lag_nr_items_day, skipped_day, color = factor(hetero_relationship))) + 
  geom_pointrange(stat='summary', fun.data='mean_cl_boot', alpha = 0.5) +
  geom_smooth(method = 'lm') +
  scale_color_colorblind(guide = F) +
  facet_wrap(~ hetero_relationship, labeller = as_labeller(c("0" = "single", "1" = "in relationship")))

library(Hmisc)
ggplot(diary %>% 
         group_by(hetero_relationship, lag_nr_items_day) %>% 
         filter(n() > 100), aes(lag_nr_items_day, skipped_day, color = factor(hetero_relationship))) + 
  geom_pointrange(stat='summary', fun.data='mean_cl_boot', alpha = 0.5) +
  geom_smooth(method = 'lm') +
  scale_color_colorblind(guide = F) +
  facet_wrap(~ hetero_relationship, labeller = as_labeller(c("0" = "single", "1" = "in relationship")))

summary(m1 <- lme4::glmer(skipped_day ~ lag_nr_items_day * hetero_relationship + (1 + lag_nr_items_day | session), diary %>% ungroup() %>% 
                      mutate(lag_nr_items_day = lag_nr_items_day/10), family = binomial))

library(effects)
plot(allEffects(m1))
coef(m1)$session %>% as_tibble(rownames = "session") %>% 
  left_join(diary %>% select(session, hetero_relationship) %>% distinct(), by = 'session', suffix = c("_est", "")) %>% 
  arrange(lag_nr_items_day) %>% 
  mutate(woman = fct_inorder(session)) %>% 
ggplot(aes(woman, lag_nr_items_day, color = factor(hetero_relationship))) +
  geom_point() +
  coord_flip()  +
  scale_color_colorblind(guide = F) +
  facet_wrap(~ hetero_relationship, labeller = as_labeller(c("0" = "single", "1" = "in relationship")))
  

summary(glm(skipped_day ~ lag_nr_items_day, diary %>% ungroup() %>% filter(between(lag_nr_items_day, 10,37)), family = binomial))
```
