---
editor_options:
  chunk_output_type: inline
title: "Routinely Randomize Potential Sources of Measurement Reactivity to Estimate and Adjust for Biases in Subjective Reports"
header-includes:
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \floatplacement{figure}{H}
output: 
  pdf_document: 
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 3
---


```{r echo=F}
knitr::opts_chunk$set(
  warning = F, message = F, 
  echo = F, error = TRUE, 
  fig.width = 15, fig.height = 6
  )
```

```{r}
options(stringsAsFactors = FALSE)
#' show two significant digits tops
options(digits = 2)
#' tend not to show scientific notation, because we're just psychologists
options(scipen = 7)
#' make output a bit wider
options(width = 110)
#' set a seed to make analyses depending on random number generation reproducible
set.seed(1710) # if you use your significant other's birthday make sure you stay together for the sake of reproducibility


#' ## Load packages
#' generate the site
library(rmarkdown)
#' set options for chunks
library(knitr)
#' my formr utility package to generate e.g. the bibliography
library(formr)
#' pretty-printed output
library(pander)
#' tidyverse date times
library(lubridate)
#' tidyverse strings
library(stringr)
#' extractor functions for models
library(broom)
#' grammar of graphics plots
library(ggplot2)
#' svg graphs
# library(svglite);
library(feather)
library(ggthemes)
library(codebook)
library(kableExtra)
library(Cairo)
library(paletteer)

#' tidyverse: has a lot of naming conflicts, so always load last
library(tidyverse)
library(broom.mixed)
library(tidylog)
options(width = 4000)
theme_set(theme_classic() + theme_pander(base_size = 18))


show_dt <- . %>% 
  mutate(term = fct_relevel(fct_recode(
    str_replace(
    str_replace(
    str_replace(
    str_replace(
    str_replace(
    str_replace(
      str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "),
      "__", " "), 
      "\\.", " "), 
       "times_item_shown", "No. times item shown"),
       "items_shown", "No. items shown"),
       "item_order", "Item order"),
       "first_day_of_item_shownTRUE", "Initial display"),
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Intercept" = "(Intercept)",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Intercept",
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  mutate_at(vars(estimate, std.error, statistic, conf.low, conf.high), ~ sprintf("%.2f", .)) %>% 
  mutate_at(vars(df), ~ sprintf("%.0f", .)) %>% 
  mutate_at(vars(p.value), ~ sprintf("%.3f", .)) %>% 
  mutate(estimate = if_else(conf.low == "NA", estimate, str_c(estimate, "\n[",conf.low, ";", conf.high, "]"))) %>% 
  select(response, term, estimate) %>% 
  spread(response, estimate)
```


```{r}
key <- keyring::key_get_raw("encrypt_data_routinely_randomise")
class(key) <- c("aes", "raw")
key <- cyphr::key_openssl(key)
s3_daily_id_answered <- cyphr::decrypt(readRDS("s3_daily_id_answered.rds"), key)
diary <- cyphr::decrypt(readRDS("diary.rds"), key)


first_page = s3_daily_id_answered  %>% 
  filter(item_name %in% c("irritable", "self_esteem", "risk_taking", "good_mood", "loneliness", "stressed")) %>% 
  group_by(session, unit_session_id) %>% 
  mutate(display_order = min_rank(display_order),
         number_of_items_shown = n()) %>%  
  arrange(session, unit_session_id, display_order) %>% 
  mutate(
        last_item = if_na(lag(label_english), "[None]")) %>% 
  ungroup() %>% 
  mutate(last_item = relevel(factor(last_item), ref =  "[None]"))
```

# Additional descriptive statistics

```{r fig.cap="Weekday distribution on diary starting day. We see that women were more likely to start the diary on Tuesday-Friday."}
ggplot(first_page %>% group_by(session) %>% filter(row_number() == 1, day_number == 0), aes(weekday)) + 
  geom_bar() +
  ggrepel::geom_label_repel(aes(x = weekday, y = stat(count), label = stat(count)), 
                            stat = "count", force = 0, size = 6) +
  scale_x_discrete("Weekday")
```

```{r fig.cap="Distributions of items."}
first_page %>% ggplot(aes(answer)) + 
  geom_bar() + 
  facet_wrap(~ label_english, scales = "free_y") +
  scale_x_continuous("Response", breaks = 0:4, labels = c("[0] less\nthan\nusual", 1, 2, 3, "[4] more\nthan\nusual")) +
  ggrepel::geom_label_repel(aes(x = answer, y = stat(count), label = stat(count)), 
                            stat = "count", force = 0, size = 3)
```

```{r fig.cap="A quick verification that fluctuation in whether a question is asked is as random as intended over time."}
first_page %>% 
  group_by(day_number) %>% 
  mutate(n_days = n_distinct(session)) %>% 
  group_by(label_english, day_number) %>% 
  summarise(n = n()/first(n_days)) %>% 
ggplot(., aes(day_number, n)) + 
  geom_line() +
  scale_y_continuous("Question asked") +
  scale_x_continuous("Day number") +
  facet_wrap(~ label_english)
```

```{r fig.cap="No strong time trends in the responses. The dashed line shows the overall mean. Y axis range is overall mean Â±1SD."}
first_page %>% 
  ggplot(., aes(day_number, answer)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = item_mean), linetype = 'dashed') + 
  geom_pointrange(position = position_dodge(width = 0.2), stat='summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.2), stat='summary', fun.data = 'mean_se') +
  scale_y_continuous("Response") +
  facet_wrap(~ label_english,scales = "free_y") +
  scale_x_continuous("Day number") +
  ggtitle("Responses over time")
```

\pagebreak

# Potential sources of measurement reactivity

## Initial elevation bias

```{r fig.cap="Figure 2, including combinations with fewer than 20 observations."}
first_page %>% 
  filter(day_number < 7) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE)) %>% 
  group_by(item_name, day_number, first_day_of_item_factor) %>% 
  # filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day_number, answer, colour = first_day_of_item_factor)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = group_mean, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat = 'summary', fun.data = 'mean_se') + 
  scale_color_colorblind("First day the\nitem was shown") +
  scale_y_continuous("Response") +
  facet_wrap(~ label_english, scales = "free_y", nrow = 2) + 
  scale_x_continuous("Day number", breaks = 0:10)
```


```{r fig.cap="An alternative, more focused visualisation of initial elevation bias. Are responses elevated when shown for the first time, even if it is not the first day of the diary? The dashed line shows the overall mean for the item. Standard errors cannot be seen, because they are so narrow (and ignore the multilevel structure of the data)"}
first_page %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE),
         day = if_else(first_day_of_item_shown, if_else(day_number == 0, 
                       "first item, \nfirst day", "first item, \nlater day"), "later day")) %>%
  group_by(item_name, day) %>% 
  filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day, answer)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = group_mean, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  scale_y_continuous("Response") +
  xlab("Day") +
  facet_wrap(~ label_english, scales = "free_y")
```



```{r fig.cap="A response bias to a Likert scale may not only affect the mean response, but also the dispersion or the propensity to choose the middle or extreme categories. Such biases would balance out and not show up in the mean response. We therefore compute the relative frequency of certain responses for first days and later days. Days on which the item is first shown have very similar response distributions as later days."}
first_page %>% 
  filter(day_number < 11) %>% 
  mutate(day = if_else(first_day_of_item_shown, if_else(day_number == 0, 
                       "first item, \nfirst day", "first item, \nlater day"), "later day")) %>%
  group_by(label_english, item_name, day) %>% 
  mutate(group_n = n_nonmissing(answer)) %>% 
  group_by(label_english, item_name, day, answer) %>% 
  summarise(rel_freq = n_nonmissing(answer)/first(group_n)) %>% 
  ggplot(., aes(answer, y = rel_freq, colour = day)) + 
  geom_line(position = position_dodge(width = 0.2)) + 
  scale_y_continuous("Relative frequency") +
  scale_x_continuous("Response", breaks = 0:4, labels = c("[0] less\nthan\nusual", 1, 2, 3, "[4] more\nthan\nusual")) +
  scale_color_colorblind() +
  facet_wrap(~ label_english, scales = "free_y")
```

\pagebreak

### Response time

```{r fig.cap="We can additionally examine whether responses slow down when items are first shown. We only examine the response time relative to the answer to the previous item here. This means the first item on each page is excluded from consideration. We do this, because responses relative to the time the page loaded are strongly biased upwards through participants who clicked the link and did something else until the page loaded, or participants who first familiarise themselves with all items. We also excluded responses that were made out of order (negative response times relative to the previous item), and responses that took longer than 30 seconds. Responses to the very first item take almost 8000ms, much longer than responses to later items. The dashed line shows the overall mean for the item. The points show means plus standard errors."}
first_page %>% 
  filter(day_number < 11) %>% 
  filter(response_time_since_previous < 1*30*1000, response_time_since_previous > 0) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(response_time_since_previous, na.rm = TRUE),
         day = if_else(first_day_of_item_shown, if_else(day_number == 0, 
                       "first item, \nfirst day", "first item, \nlater day"), "later day")) %>%
  group_by(item_name, day) %>% 
  filter(n_nonmissing(response_time_since_previous) > 20) %>% 
  ggplot(., aes(day, response_time_since_previous/1000)) + 
  geom_hline(aes(yintercept = group_mean/1000, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  scale_y_continuous("Response time relative to previous item (in s)") +
  xlab("Day") +
  facet_wrap(~ label_english, scales = "free_y")
```


```{r fig.cap="We can also examine response times as in Figure 2, but switching to the time series view somewhat clutters the display. Limited to combinations with at least 20 responses. Lines show 10% trimmed means."}
first_page %>% 
  filter(day_number < 11, response_time_since_previous < 30*1000, response_time_since_previous > 0) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE)) %>% 
  group_by(item_name, day_number, first_day_of_item_factor) %>% 
  filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day_number, response_time_since_previous/1000, colour = first_day_of_item_factor)) + 
  # geom_pointrange(alpha = 0.3, position = position_dodge(width = 0.2), stat ='summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat ='summary', fun.y = function(x) { mean(x, na.rm =T, trim = 0.1) }) +
  scale_color_colorblind("First day the\nitem was shown") +
  scale_x_continuous("Day number", breaks = 0:10) +
  scale_y_continuous("Response time (in s) since previous item") +
  facet_wrap(~ label_english)
```


### Only participants who participated every day in the first week


```{r fig.cap="Figure 2, but only with those who didn't miss a day in the first week (ruling out selective dropout as an explanation). Patterns seem unchanged."}
first_page %>% 
  filter(day_number < 7, didntmissfirstweek == TRUE) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE)) %>% 
  group_by(item_name, day_number, first_day_of_item_factor) %>% 
  filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day_number, answer, colour = first_day_of_item_factor)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = group_mean, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat = 'summary', fun.data = 'mean_se') + 
  scale_color_colorblind("First day the\nitem was shown") +
  scale_y_continuous("Response") +
  facet_wrap(~ label_english, scales = "free_y", nrow = 2) + 
  scale_x_continuous("Day number", breaks = 0:10)
```

## Item order

```{r fig.cap="As above, we can not only examine the mean but also the response distribution according to item order."}
first_page %>% 
  group_by(label_english, item_name, display_order) %>% 
  mutate(group_n = n_nonmissing(answer)) %>% 
  group_by(label_english, item_name, display_order, answer) %>% 
  summarise(rel_freq = n_nonmissing(answer)/first(group_n)) %>% 
  ggplot(., aes(answer, y = rel_freq, colour = display_order, group = display_order)) + 
  geom_line(position = position_dodge(width = 0.2)) + 
  scale_color_continuous("Item order") +
  scale_y_continuous("Relative frequency") +
  scale_x_continuous("Response", breaks = 0:4, labels = c("[0] less\nthan\nusual", 1, 2, 3, "[4] more\nthan\nusual")) +
  facet_wrap(~ label_english, scales = "free_y")
```


```{r fig.cap="Again, we can also examine the response time to each item according to item order.  The line shows the 10% trimmed means, the points show means plus standard errors. We excluded responses that were made out of order (negative response times relative to the previous item), and responses that took longer than 30 seconds."}
first_page %>% filter(response_time_since_previous < 1*30*1000, response_time_since_previous > 0, display_order > 1) %>% 
  ggplot(., aes(display_order, response_time_since_previous/1000)) + 
  geom_pointrange(alpha = 0.3, position = position_dodge(width = 0.2), stat ='summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat ='summary', fun.y = function(x) { mean(x, na.rm =T, trim = 0.1) }) +
  scale_y_continuous("Response time (in s) since previous item") +
  xlab("Item order") +
  facet_wrap(~ label_english, scales = 'free_y')
```


## Number of items shown
As mentioned above, the number of items shown is also a randomised variable.
It is in turn confounded with item order, because items shown on a page with more items
are likely to have a later item order. Most importantly, when only one item is shown, item order
is necessarily `1`.

```{r fig.cap="Response means according to the number of items shown. The Y axis scale is displayed from each itemâs mean Â± 1 SD; values ranged from 0 to 4. The standard errors for the means do not account for the person-level structure of the data."}
first_page %>% 
  ggplot(., aes(number_of_items_shown, answer)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_pointrange(position = position_dodge(width = 0.2), stat ='summary', fun.data = 'mean_se') + 
  # geom_line(position = position_dodge(width = 0.4), stat ='summary', fun.data = 'median_hilow') + 
  scale_y_continuous("Response") +
  xlab("No. of items shown") +
  facet_wrap(~ label_english, scales = 'free_y')
```


```{r  fig.cap="Again, we can also examine the response time to each item according to number of items shown. The line shows the 10% trimmed means, the points show means plus standard errors. We excluded responses that were made out of order (negative response times relative to the previous item), and responses that took longer than 30 seconds."}
first_page %>% filter(response_time_since_previous < 1*30*1000, response_time_since_previous > 0, display_order > 1) %>% 
  ggplot(., aes(number_of_items_shown, response_time_since_previous/1000)) + 
  geom_pointrange(alpha = 0.3, position = position_dodge(width = 0.2), stat ='summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat ='summary', fun.y = function(x) { mean(x, na.rm =T, trim = 0.1) }) +
  scale_y_continuous("Response time (in s) since previous item") +
  scale_x_continuous("No. of items shown", breaks = 1:6) +
  facet_wrap(~ label_english, scales = 'free_y')
```

## Last item

```{r fig.cap="A different way to think about item order is to consider the identity of the immediately preceding item. The Y axis here shows which item (if any) preceded the given item. The X axes include the global mean Â± 1 global standard deviation for each item.  Standard errors (not visible) do not account for the multilevel structure of the data."}
first_page %>% 
  ggplot(., aes(last_item, answer)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = item_mean), linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat ='summary', fun.data = 'mean_se') + 
  # geom_line(position = position_dodge(width = 0.4), stat ='summary', fun.data = 'median_hilow') + 
  scale_y_continuous("Response") +
  coord_flip() +
  facet_wrap(~ label_english, scales = 'free_x')
```


```{r fig.cap="As above, we can not only examine the mean but also the distribution of each response."}
first_page %>% 
  group_by(label_english, item_name, last_item) %>% 
  mutate(group_n = n_nonmissing(answer)) %>% 
  group_by(label_english, item_name, last_item, answer) %>% 
  summarise(rel_freq = n_nonmissing(answer)/first(group_n)) %>% 
  ggplot(., aes(answer, y = rel_freq, colour = last_item)) + 
  geom_line(position = position_dodge(width = 0.2)) + 
  scale_color_colorblind("Last item") +
  scale_y_continuous("Relative frequency") +
  scale_x_continuous("Response", breaks = 0:4, labels = c("[0] less\nthan\nusual", 1, 2, 3, "[4] more\nthan\nusual")) +
  facet_wrap(~ label_english, scales = "free_y")
```

\pagebreak

# Multilevel analysis 

```{r fig.cap="Figure 5 only showed the randomised variables. Here, we additionally show the estimates for the covariates.",fig.width=15,fig.height=11}
predictors <- first_page %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )
library(lme4)
library(lmerTest)
library(broom.mixed)

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 | session), data = .))

all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.95)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    first_page %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.3, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```


```{r}
all_biases %>% show_dt() %>% 
   knitr::kable(caption = "Multilevel regression coefficients", format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  footnote("Estimates from the multilevel regression model displayed in Figure 5, with 95% confidence intervals.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "2.5cm") %>% 
  column_spec(2:7, width = "1.7cm")
```

\pagebreak

## Robustness checks
Here, we examine several alternative model specifications to see whether the results are robust to additional constraints or relaxed assumptions.

### Complete first week

```{r fig.cap="Here, we fit the same model as before, but include only participants who participated the entire first week.",fig.width=15,fig.height=10}
predictors <- first_page %>% 
  filter(didntmissfirstweek) %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )
library(lme4)
library(lmerTest)
library(broom.mixed)

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 | session), data = .))

all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.95)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    first_page %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.2, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```

\pagebreak

### Last item identity
```{r fig.cap="Here, we additionally test for an effect of last item identity (which is heavily collinear with item order).",fig.width=15,fig.height=14}
predictors <- first_page %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )
library(lme4)
library(lmerTest)
library(broom.mixed)

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ last_item + weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 | session), data = .))

all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.95)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    first_page %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(str_replace(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), "last_item", "LI: "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.2, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ last_item + weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ as.data.frame(anova(
    lmer(answer ~ items_shown + item_order + times_item_shown + day_number + refer_time_period +  (1 | session), data = ., REML = FALSE),
    lmer(answer ~ last_item + items_shown + item_order + times_item_shown + day_number + refer_time_period +  (1 | session), data = .), REML = FALSE)
    )) %>% 
  bind_rows(.id = "response") %>% 
  select(response, df, AIC, logLik, statistic, Chi.Df, p.value) %>% 
  knitr::kable(caption = "Model comparison", format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  footnote("Do models additionally accounting for last item identity fit better? We test this separately because item order 1 and last item \"[None]\" are identical, and estimates become less precise because of similar, less severe multicollinearity.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position")
```


### Varying effects

```{r fig.cap="Here, we allow the effect of the randomised variables to vary by woman.",fig.width=15,fig.height=10}
predictors <- first_page %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )
library(lme4)
library(lmerTest)
library(broom.mixed)

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 + items_shown + item_order + first_day_of_item_shown | session), data = .))

all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.95)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    first_page %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.2, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 + items_shown + item_order + first_day_of_item_shown | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```

\pagebreak

```{r}
all_biases %>% show_dt() %>% 
   knitr::kable(caption = "Multilevel regression coefficients", format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  footnote("Estimates from the multilevel regression model with varying slopes. With 95% confidence intervals.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "2.5cm") %>% 
  column_spec(2:7, width = "1.7cm")
```

\pagebreak

### Nonlinear effects

```{r fig.cap="Here, we allow the effects of the randomised variables to be nonlinear.",fig.width=15,fig.height=15}
predictors <- first_page %>% 
  mutate(item_order = factor(display_order),
         times_item_shown = times_item_answered_factor,
         items_shown = factor(number_of_items_shown)
         )
library(lme4)
library(lmerTest)
library(broom.mixed)

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 | session), data = .))

all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.95)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    first_page %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.2, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```


\pagebreak

# Other items

We focused on the most general items on the first page of our study.
However, the diary also contained randomised (in order and odds of appearing) items about sexual desire, time use, and partner jealousy, among others. We show that
the overall results (that residualising for estimated biases has negligible effects) holds here too, even though the partner jealousy items were asked on a response scale from "not at all" to "very much", the desire items on a scale of "very inaccurate" to "very accurate", and the time use items on the same "less than usual" to "more than usual" scale as the items on the first page.

## Time items
```{r}
time_items = s3_daily_id_answered  %>% 
  filter(item_name %starts_with% "time_") %>% 
  group_by(session, unit_session_id) %>% 
  mutate(display_order = min_rank(display_order),
         number_of_items_shown = n()) %>%  
  arrange(session, unit_session_id, display_order) %>% 
  mutate(
        last_item = if_na(lag(label_english), "[None]")) %>% 
  ungroup() %>% 
  mutate(last_item = relevel(factor(last_item), ref =  "[None]"))
```

On  a "less than usual" to "more than usual" response scale.



```{r}
time_items %>% group_by(item_name, label_english) %>% 
  summarise(women = n_distinct(session),
            days = n_distinct(unit_session_id)) %>% 
  knitr::kable(format = "latex", caption = "How often did how many women see each item?") %>% 
  kable_styling(latex_options = "hold_position")
```

```{r}
time_items %>% 
  filter(day_number < 7) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE)) %>% 
  group_by(item_name, day_number, first_day_of_item_factor) %>% 
  filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day_number, answer, colour = first_day_of_item_factor)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = group_mean, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat = 'summary', fun.data = 'mean_se') + 
  scale_color_colorblind("First day the\nitem was shown") +
  scale_y_continuous("Response") +
  facet_wrap(~ label_english, scales = "free_y", nrow = 2) + 
  scale_x_continuous("Day number", breaks = 0:10)
```


```{r fig.cap="Estimates for biases and covariates for the time items.",fig.width=15,fig.height=10}
predictors <- time_items %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 | session), data = .))


all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.99)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    time_items %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.2, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```

\pagebreak

```{r}
all_biases %>% show_dt() %>% 
   knitr::kable(caption = "Multilevel regression coefficients", format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  footnote("Estimates from the multilevel regression model displayed in Figure 5, with 95% confidence intervals.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "2.5cm") %>% 
  column_spec(2:7, width = "1.9cm")
```

\pagebreak

## Desire items

```{r}
desire_items = s3_daily_id_answered  %>% 
  filter(item_name %in% c("in_pair_desire_7", "in_pair_desire_8",
                     "in_pair_desire_10", "in_pair_desire_11",
                     "in_pair_desire_13", "in_pair_desire_14")) %>% 
  group_by(session, unit_session_id) %>% 
  mutate(display_order = min_rank(display_order),
         number_of_items_shown = n()) %>%  
  arrange(session, unit_session_id, display_order) %>% 
  mutate(
        last_item = if_na(lag(label_english), "[None]")) %>% 
  ungroup() %>% 
  mutate(last_item = relevel(factor(last_item), ref =  "[None]"))
```


On a "very inaccurate" to "very accurate" response scale.

```{r}
desire_items %>% group_by(label_english) %>% 
  summarise(women = n_distinct(session),
            days = n_distinct(unit_session_id)) %>% 
  knitr::kable(format = "latex", caption = "How often did how many women see each item?") %>% 
  kable_styling(latex_options = "hold_position")
```


```{r}
desire_items %>% 
  filter(day_number < 7) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE),
         label_english = str_wrap(label_english, 30)) %>% 
  group_by(item_name, day_number, first_day_of_item_factor) %>% 
  filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day_number, answer, colour = first_day_of_item_factor)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = group_mean, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat = 'summary', fun.data = 'mean_se') + 
  scale_color_colorblind("First day the\nitem was shown") +
  scale_y_continuous("Response") +
  facet_wrap(~ label_english, scales = "free_y", nrow = 2) + 
  scale_x_continuous("Day number", breaks = 0:10)
```


```{r fig.cap="Estimates for biases and covariates for the desire items.",fig.width=15,fig.height=13}
predictors <- desire_items %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )

complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 | session), data = .))


all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.99)) %>% 
  bind_rows(.id = "response") 


all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    desire_items %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(item = str_wrap(item, 30),
         term = fct_relevel(fct_recode(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.2, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```

\pagebreak

```{r}
all_biases %>% 
  mutate(response = str_sub(response, 9)) %>% 
  show_dt() %>% 
   knitr::kable(caption = "Multilevel regression coefficients", format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  footnote("Estimates from the multilevel regression model displayed in Figure 5, with 95% confidence intervals.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "2.4cm") %>% 
  column_spec(2:7, width = "1.8cm")
```

\pagebreak

## Retention items
```{r}
retention_items = s3_daily_id_answered  %>% 
  filter(item_name %contains% "mate_retention") %>% 
  group_by(session, unit_session_id) %>% 
  mutate(display_order = min_rank(display_order),
         number_of_items_shown = n()) %>%  
  arrange(session, unit_session_id, display_order) %>% 
  mutate(
        last_item = if_na(lag(label_english), "[None]")) %>% 
  ungroup() %>% 
  mutate(last_item = relevel(factor(last_item), ref =  "[None]"))
```

On a "not at all" to "very much" response scale.

```{r}
retention_items %>% 
  group_by(item_name, label_english) %>% 
  summarise(women = n_distinct(session),
            days = n_distinct(unit_session_id)) %>% 
  knitr::kable(format = "latex", caption = "How often did how many women see each item?") %>% 
  kable_styling(latex_options = "hold_position")
```


```{r}
retention_items %>% 
  filter(day_number < 7) %>% 
  group_by(item_name) %>% 
  mutate(group_mean = mean(answer, na.rm = TRUE)) %>% 
  group_by(item_name, day_number, first_day_of_item_factor) %>% 
  filter(n_nonmissing(answer) > 20) %>% 
  ggplot(., aes(day_number, answer, colour = first_day_of_item_factor)) + 
  geom_blank(aes(y = item_mean, ymin = item_mean - item_sd, ymax = item_mean + item_sd)) +
  geom_hline(aes(yintercept = group_mean, group = label), color = "gray", linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.2), stat = 'summary', fun.data = 'mean_se') + 
  geom_line(position = position_dodge(width = 0.4), stat = 'summary', fun.data = 'mean_se') + 
  scale_color_colorblind("First day the\nitem was shown") +
  scale_y_continuous("Response") +
  facet_wrap(~ label_english, scales = "free_y", nrow = 2) + 
  scale_x_continuous("Day number", breaks = 0:10)
```



```{r fig.cap="Estimates for biases and covariates for the mate retention items.",fig.width=15,fig.height=10}
predictors <- retention_items %>% 
  mutate(item_order = display_order,
         times_item_shown = times_item_answered,
         items_shown = number_of_items_shown
         )
complex_mods <-  predictors %>% 
  split(.$item_name) %>%
  map(~ lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period +  (1 | session), data = .))


all_biases <- complex_mods %>% 
  map(~ tidy(., conf.int = TRUE, conf.level = 0.99)) %>% 
  bind_rows(.id = "response")

all_biases %>% 
  filter(is.na(group)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(
    retention_items %>% select(response = item_name, item = label_english, item_mean, item_sd) %>% distinct()
  ) %>% 
  mutate(term = fct_relevel(fct_recode(str_replace(str_replace(term, "weekday", ""), "day_number_factor", "Day "), 
                           "No. times item shown" = "times_item_shown",
                           "Ref: since last entry" = "refer_time_periodlast entry",
                           "No. items shown" = "items_shown",
                           "Item order" = "item_order",
                           "Initial display" = "first_day_of_item_shownTRUE",
                           "Day" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)1",
                           "Day^2" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)2",
                           "Day^3" = "poly(scale(day_number, scale = F)/10, degree = 3, raw = T)3"),
                           "Initial display" ,
                           "No. items shown", 
                           "No. times item shown", 
                           "Item order",
                           "Ref: since last entry",
                           "Sunday","Saturday",  "Friday", "Thursday","Wednesday",  "Tuesday", 
                           "Day^3",
                           "Day^2",
                           "Day")
                           ) %>% 
  # filter(term != "refer_time_periodlast entry", 
         # str_sub(term, 1, 10) != "day_number", term != "(Intercept)", !is.na(conf.high)) %>% 
  ggplot(aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_rect(ymin = -0.1, ymax = 0.1, xmin = -Inf, xmax = Inf, fill = "lightblue", alpha = 0.5) +
  # geom_blank(aes(y = estimate, ymin = estimate - item_sd, ymax = estimate + item_sd)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  ggrepel::geom_text_repel(aes(label = sprintf("%.2f",estimate)), force = 0, nudge_x = 0.2, segment.size = 0) +
  facet_wrap(~ item) +
  geom_pointrange() +
  scale_y_continuous("Estimated effect on response (95% CI)") +
  scale_x_discrete("Predictor") +
  coord_flip()
```

```{r}
predictors %>% 
  split(.$label_english) %>%
  map(~ cor(residuals(lmer(answer ~ weekday + day_number_factor + refer_time_period + (1 | session), .)), residuals(lmer(answer ~ weekday + items_shown + item_order + first_day_of_item_shown + day_number_factor + refer_time_period + (1 | session), data = .)))^2) %>% 
  bind_rows() %>% 
  gather(`Response variable`, Correlation) %>% 
  mutate(Correlation = sprintf("%.2f", Correlation)) %>% 
  arrange(Correlation) %>% 
  knitr::kable(caption = "Residual correlation", format = "latex",  booktabs = TRUE) %>% 
  footnote("Correlation between the residuals of a covariate-only model and a model additionally including the randomised variables.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "5cm") %>% 
  column_spec(2, width = "1.5cm")
```

\pagebreak

```{r}
all_biases %>% show_dt() %>% 
   knitr::kable(caption = "Multilevel regression coefficients", format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  footnote("Estimates from the multilevel regression model displayed in Figure 5, with 95% confidence intervals.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position") %>% 
  column_spec(1, width = "2.5cm") %>% 
  column_spec(2:7, width = "2.5cm")
```

\pagebreak

# Dropout

The additional workload on each day (total number of randomised items that were shown)
is a random variable, conditional on relationship status (women in relationships had
to answer slightly more questions, some of which were also randomised in appearance). 
We can use this variable to predict whether a woman who had to answer more questions
is less likely to answer the diary on the next day.

```{r fig.cap="Distribution of the number of randomised items assigned on each day, split by relationship status."}
ggplot(diary, aes(nr_items_day_done, fill = factor(hetero_relationship))) + 
  geom_bar() +
  scale_fill_colorblind(guide = FALSE) +
  scale_x_continuous("No. of randomised items answered") +
  facet_wrap(~ hetero_relationship, labeller = as_labeller(c("0" = "single", "1" = "in relationship")))

library(Hmisc)
```

```{r fig.cap="Is there any relationship between the number of items today and whether the participant takes part again on the next day? Only randomised variable counts with at least 100 instances are shown. The line and shading reflects a fit from a logistic regression that does not account for the multilevel structure of the data."}
ggplot(diary %>% 
         group_by(hetero_relationship, lag_nr_items_day) %>% 
         filter(n() > 100), aes(lag_nr_items_day, skipped_day, color = factor(hetero_relationship))) + 
  geom_pointrange(stat='summary', fun.data='mean_cl_boot', alpha = 0.5) +
  geom_smooth(method = 'glm', method.args = list(family = binomial())) +
  scale_color_colorblind(guide = F) +
  scale_y_continuous("Skipped next day") +
  scale_x_continuous("No. of randomised items answered") +
  facet_wrap(~ hetero_relationship, labeller = as_labeller(c("0" = "single", "1" = "in relationship")))
```

```{r}
diary_dropout <- diary %>% ungroup() %>% 
                      mutate(lag_nr_items_day = lag_nr_items_day/10) %>% drop_na(lag_nr_items_day)
m0 <- lme4::glmer(skipped_day ~ hetero_relationship + (1 | session), diary_dropout, family = binomial)
m1 <- lme4::glmer(skipped_day ~ lag_nr_items_day * hetero_relationship + (1 + lag_nr_items_day | session), diary_dropout, family = binomial)
tidy(anova(m0, m1)) %>% 
  select(term, df, AIC, logLik, statistic, Chi.Df, p.value) %>% 
  knitr::kable(caption = "Model comparison", format = "latex", booktabs = TRUE, longtable = TRUE) %>%
  footnote("Can we predict whether participants will skip the next day any better through the randomised number of items they answered today? Compares a multilevel model adjusted only for being in a relationship with one that allows for an effect of the no. of randomised items, which is allowed to vary between women and moderated by relationship status.", threeparttable = TRUE) %>% 
  kable_styling(latex_options = "hold_position")
```

